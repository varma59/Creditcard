{"cells":[{"cell_type":"markdown","source":["# Creating, Evaluating, and Deploying a Fraud Detection System"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"61a232a2-64a2-4f18-8bf6-75741a345a81"},{"cell_type":"markdown","source":["## Introduction\n","\n","In this notebook, we'll demonstrate the Microsoft Fabric data science workflow with an end-to-end example. The scenario is to build a fraud detection system that relies on ML algorithms trained on historical data consisting of previous examples of fraud in order to understand the characteristic patterns of the fraudulent events to recognize them once they recur.\n","\n","The summary of main steps we take in this notebook are as following:\n","\n","1. Install custom libraries\n","2. Load and process the data\n","3. Understand the data using exploratory data analysis\n","4. Train a machine learning model using Scikit-Learn and MLflow\n","5. Save and register the best performing machine learning model\n","6. Load the machine learning model for scoring and make predictions\n","\n","#### Prerequisites\n","- Have a lakehouse added to this notebook. We will be downloading data from a public blob, and storing that in the lakehouse. "],"metadata":{},"id":"f3248560-b758-4daa-8f66-f86024368ce7"},{"cell_type":"markdown","source":["## Step 1: Install Custom Libraries\n","When developing a machine learning model or doing ad-hoc data analysis, we may need to quickly install a custom library for your Apache Spark session. To do this, we have two choices. \n","\n","1. We can use the in-line installation capabilities (e.g., pip, conda, etc.) to quickly get started with new libraries. In this notebook, we'll use `imblearn` which first needs to be installed.\n","\n","```python\n","# Use pip to install libraries\n","%pip install <library name>\n","\n","# Use conda to install libraries\n","%conda install <library name>\n"," \n","```\n","2. Alternatively, we can install the required libraries in the workspace. Navigate to the workspace setting as shown below and then click on Library management.\n","\n","<img style=\"float: left;\" src=\"https://synapseaisolutionsa.blob.core.windows.net/public/Credit_Card_Fraud_Detection/librarymanagement2.png\"  width=\"45%\" height=\"10%\">\n","<img style=\"float: left;\" src=\"https://synapseaisolutionsa.blob.core.windows.net/public/Credit_Card_Fraud_Detection/librarymanagement1.png\"  width=\"45%\" height=\"10%\"> \n"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"09f17a8a-dc0c-4363-bb0c-3fc26ebc9031"},{"cell_type":"markdown","source":["We can then select how to install the required libraries, e.g., add from PyPi, add from .yml file, etc. Since we are using PyPi, we click on + Add from PyPi and then select the desired libraries and their corresponding versions from the drop down and then click on the Apply. This will automatically install all selected libraries in the workspace.\n","\n","<img src=\"https://synapseaisolutionsa.blob.core.windows.net/public/Credit_Card_Fraud_Detection/librarymanagement3.png\"  width=\"40%\" height=\"10%\">"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"72a2db10-43e3-43a4-b34f-81c33b3ba210"},{"cell_type":"markdown","source":["#### Introduction to SMOTE\n","\n","The problem with imbalanced classification is that there are too few examples of the minority class for a model to effectively learn the decision boundary. Synthetic Minority Oversampling Technique (SMOTE) is the most widely used approach to synthesize new samples for the minority class. You can read more about SMOTE [here](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html#) and [here](https://imbalanced-learn.org/stable/over_sampling.html#smote-adasyn).\n","\n","In order to install Imbalanced-learn (imported as imblearn) which is a library for SMOTE, we will proceed with the first approach in Step 1.\n"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"e10f97cd-c4eb-43f2-8ed0-c3833c30221b"},{"cell_type":"code","source":["# Install imblearn for SMOTE using pip\n","%pip install imblearn"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":null,"statement_id":null,"state":"session_error","livy_statement_state":null,"queued_time":"2023-08-23T12:25:27.9131817Z","session_start_time":"2023-08-23T12:25:28.0882721Z","execution_start_time":null,"execution_finish_time":null,"spark_jobs":null,"parent_msg_id":"c837837b-29f3-43d5-8288-9035a685e138"},"text/plain":"StatementMeta(, , , SessionError, )"},"metadata":{}},{"output_type":"error","ename":"LivyHttpRequestFailure","evalue":"[InternalServerError] Internal server error encountered while preparing service authentication tokens. HTTP status code: 500.","traceback":["LivyHttpRequestFailure: [InternalServerError] Internal server error encountered while preparing service authentication tokens. HTTP status code: 500."]}],"execution_count":7,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}},"cellStatus":"{}"},"id":"ee593ea9-5a27-451d-8959-293fc38986f7"},{"cell_type":"markdown","source":["## Step 2: Load the Data\n","The fraud detection dataset contains credit card transactions made by European cardholders in September 2013 over the course of two days. The dataset only contains numerical features, which is the result of a Principal Component Analysis (PCA) transformation that was done on the original features. The only features that haven't been transformed with PCA are \"Time\" and \"Amount\". In order to protect confidentiality, we can't provide the original features or more background information about the dataset.\n","\n","- The features \"V1, V2, V3, â€¦, V28\" are the principal components obtained with PCA.\n","- The feature \"Time\" contains the seconds elapsed between each transaction and the first transaction in the dataset.\n","- The feature \"Amount\" is the transaction amount. This feature can be used for example-dependent cost-sensitive learning.\n","- The column \"Class\" is the response (target) variable and take the value 1 for fraud and 0 otherwise.\n","\n","Note that out of the 284,807 transactions, only 492 are fraudulent. Therefore, the minority class (fraud) only accounts for around 0.172% of the data which makes the dataset highly imbalanced.\n","\n","- creditcard.csv\n","\n","|\"Time\"|\"V1\"|\"V2\"|\"V3\"|\"V4\"|\"V5\"|\"V6\"|\"V7\"|\"V8\"|\"V9\"|\"V10\"|\"V11\"|\"V12\"|\"V13\"|\"V14\"|\"V15\"|\"V16\"|\"V17\"|\"V18\"|\"V19\"|\"V20\"|\"V21\"|\"V22\"|\"V23\"|\"V24\"|\"V25\"|\"V26\"|\"V27\"|\"V28\"|\"Amount\"|\"Class\"|\n","|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n","|0|-1.3598071336738|-0.0727811733098497|2.53634673796914|1.37815522427443|-0.338320769942518|0.462387777762292|0.239598554061257|0.0986979012610507|0.363786969611213|0.0907941719789316|-0.551599533260813|-0.617800855762348|-0.991389847235408|-0.311169353699879|1.46817697209427|-0.470400525259478|0.207971241929242|0.0257905801985591|0.403992960255733|0.251412098239705|-0.018306777944153|0.277837575558899|-0.110473910188767|0.0669280749146731|0.128539358273528|-0.189114843888824|0.133558376740387|-0.0210530534538215|149.62|\"0\"|\n","|0|1.19185711131486|0.26615071205963|0.16648011335321|0.448154078460911|0.0600176492822243|-0.0823608088155687|-0.0788029833323113|0.0851016549148104|-0.255425128109186|-0.166974414004614|1.61272666105479|1.06523531137287|0.48909501589608|-0.143772296441519|0.635558093258208|0.463917041022171|-0.114804663102346|-0.183361270123994|-0.145783041325259|-0.0690831352230203|-0.225775248033138|-0.638671952771851|0.101288021253234|-0.339846475529127|0.167170404418143|0.125894532368176|-0.00898309914322813|0.0147241691924927|2.69|\"0\"|\n"],"metadata":{},"id":"39e326f0-e4f8-463c-a0d4-d6d96a2544b7"},{"cell_type":"markdown","source":["**By defining below parameters, we can apply this notebook on different datasets easily.**"],"metadata":{},"id":"1c5fecbb-55f1-4575-ae06-224e26b60375"},{"cell_type":"code","source":["IS_CUSTOM_DATA = False  # if True, dataset has to be uploaded manually\n","\n","TARGET_COL = \"Class\"  # target column name\n","IS_SAMPLE = False  # if True, use only <SAMPLE_ROWS> rows of data for training, otherwise use all data\n","SAMPLE_ROWS = 5000  # if IS_SAMPLE is True, use only this number of rows for training\n","\n","DATA_FOLDER = \"Files/fraud-detection/\"  # folder with data files\n","DATA_FILE = \"creditcard.csv\"  # data file name\n","\n","EXPERIMENT_NAME = \"aisample-fraud\"  # mlflow experiment name"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":null,"statement_id":null,"state":"cancelled","livy_statement_state":null,"queued_time":"2023-08-23T12:25:03.0885543Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":"2023-08-23T12:25:04.9558177Z","spark_jobs":null,"parent_msg_id":"fafe9099-8e97-486f-900b-0efb800def27"},"text/plain":"StatementMeta(, , , Cancelled, )"},"metadata":{}}],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}},"cellStatus":"{}"},"id":"398877d9-fc16-48cc-b8b4-2f7fa264cda7"},{"cell_type":"markdown","source":["### Download dataset and Upload to lakehouse\n","\n","The following code will download a publicly available version of the the dataset and then store it in a Fabric Lakehouse.\n","\n","**Please add a lakehouse to the notebook before running it. Failure to do so will result in an error.**\n","\n","Instructions to add a lakehouse to the notebook can be found [here](https://aka.ms/fabric/addlakehouse)."],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"cfd8b439-8c0c-4de4-97a3-3c3f397de6c8"},{"cell_type":"code","source":["if not IS_CUSTOM_DATA:\n","    # Download data files into lakehouse if not exist\n","    import os, requests\n","\n","    remote_url = \"https://synapseaisolutionsa.blob.core.windows.net/public/Credit_Card_Fraud_Detection\"\n","    fname = \"creditcard.csv\"\n","    download_path = f\"/lakehouse/default/{DATA_FOLDER}/raw\"\n","\n","    if not os.path.exists(\"/lakehouse/default\"):\n","        raise FileNotFoundError(\"Default lakehouse not found, please add a lakehouse and restart the session.\")\n","    os.makedirs(download_path, exist_ok=True)\n","    if not os.path.exists(f\"{download_path}/{fname}\"):\n","        r = requests.get(f\"{remote_url}/{fname}\", timeout=30)\n","        with open(f\"{download_path}/{fname}\", \"wb\") as f:\n","            f.write(r.content)\n","    print(\"Downloaded demo data files into lakehouse.\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":null,"statement_id":null,"state":"cancelled","livy_statement_state":null,"queued_time":"2023-08-23T12:25:03.2725946Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":"2023-08-23T12:25:04.9561635Z","spark_jobs":null,"parent_msg_id":"87cb6f17-5fd8-410c-b5bf-0898edddc6c2"},"text/plain":"StatementMeta(, , , Cancelled, )"},"metadata":{}}],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}},"cellStatus":"{}"},"id":"e2b23a6e-2dc7-4501-b429-d51fb7982456"},{"cell_type":"markdown","source":["We start recording the time it takes to run this notebook."],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"6a57aee7-4b7e-4f6e-a55d-a8a88818b96a"},{"cell_type":"code","source":["# Record the notebook running time\n","import time\n","\n","ts = time.time()\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":null,"statement_id":null,"state":"cancelled","livy_statement_state":null,"queued_time":"2023-08-23T12:25:03.4871563Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":"2023-08-23T12:25:04.9564604Z","spark_jobs":null,"parent_msg_id":"f87add87-cb0b-46e0-834b-72c0151b3089"},"text/plain":"StatementMeta(, , , Cancelled, )"},"metadata":{}}],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}},"cellStatus":"{}"},"id":"6f1b1389-e53c-4c0a-8459-4b2086f62176"},{"cell_type":"markdown","source":["### Setup the MLflow experiment tracking\n","\n","Experiment tracking is the process of saving all experiment related information that we care about for every experiment we run. This is important because for some experiments, we can easily observe that there is no way we will be able to get better results. Therefore, we will be better off simply stopping them and trying a new experiment. \n","\n","Synapse Data Science in Microsoft Fabric includes autologging, which significantly reduces the amount of code required to automatically log the parameters, metrics, and items of a machine learning model during training. This feature extends MLflow autologging capabilities and is deeply integrated into the Synapse Data Science in Microsoft Fabric experience. Using autologging, we can easily track and compare the performance of different models and experiments without the need for manual tracking. Further information about how to perform autologging can be found [here](https://aka.ms/fabric-autologging)."],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"90c0a880-9f3a-4c32-b4ce-615327232184"},{"cell_type":"code","source":["# Setup mlflow for experiment tracking\n","import mlflow\n","\n","mlflow.set_experiment(EXPERIMENT_NAME)\n","mlflow.autolog(disable=True)  # disable mlflow autologging"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":null,"statement_id":null,"state":"cancelled","livy_statement_state":null,"queued_time":"2023-08-23T12:25:03.7393622Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":"2023-08-23T12:25:04.9567313Z","spark_jobs":null,"parent_msg_id":"db5a6a54-e2ac-4ed8-a804-de49a4224a0d"},"text/plain":"StatementMeta(, , , Cancelled, )"},"metadata":{}}],"execution_count":null,"metadata":{"cellStatus":"{}"},"id":"f8c7e126-3c2d-440c-8621-a9d55878af59"},{"cell_type":"markdown","source":["### Read raw date data from the lakehouse"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"f521e57f-0a4b-4833-adb1-55491d1b15bc"},{"cell_type":"code","source":["df = (\n","    spark.read.format(\"csv\")\n","    .option(\"header\", \"true\")\n","    .option(\"inferSchema\", True)\n","    .load(f\"{DATA_FOLDER}/raw/{DATA_FILE}\")\n","    .cache()\n",")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":null,"statement_id":null,"state":"cancelled","livy_statement_state":null,"queued_time":"2023-08-23T12:25:04.0891123Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":"2023-08-23T12:25:04.9569633Z","spark_jobs":null,"parent_msg_id":"3d06084b-c591-4a65-8123-28a089e6b136"},"text/plain":"StatementMeta(, , , Cancelled, )"},"metadata":{}}],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}},"cellStatus":"{}"},"id":"361b199d-f45c-4351-9c38-83f73659afbf"},{"cell_type":"markdown","source":["## Step 3: Exploratory Data Analysis\n","\n","We can explore using the `display` command to view high-level statistics of the dataset. You can learn more about visualization in Microsoft Fabric [here](https://aka.ms/fabric/visualization)."],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"a1201a0d-c19a-434b-acec-1cf68dd2508f"},{"cell_type":"code","source":["display(df)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":null,"statement_id":null,"state":"cancelled","livy_statement_state":null,"queued_time":"2023-08-23T12:25:04.4686592Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":"2023-08-23T12:25:04.9572057Z","spark_jobs":null,"parent_msg_id":"f485de99-f494-4e79-b372-369fb815bf5b"},"text/plain":"StatementMeta(, , , Cancelled, )"},"metadata":{}}],"execution_count":null,"metadata":{"cellStatus":"{}"},"id":"1f2da613-5c7a-4878-a388-823032afe017"},{"cell_type":"code","source":["# Print dataset basic information\n","print(\"records read: \" + str(df.count()))\n","print(\"Schema: \")\n","df.printSchema()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":null,"statement_id":null,"state":"cancelled","livy_statement_state":null,"queued_time":"2023-08-23T12:25:04.76076Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":"2023-08-23T12:25:04.9574351Z","spark_jobs":null,"parent_msg_id":"5b67ca10-0cd4-4f9c-95fa-189a02c17e0f"},"text/plain":"StatementMeta(, , , Cancelled, )"},"metadata":{}}],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}},"cellStatus":"{}"},"id":"fae839a8-a355-40ac-8eac-48379391d065"},{"cell_type":"markdown","source":["We need to cast the columns into the correct types."],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"a9616519-d17e-45ed-8756-529e2faf6b32"},{"cell_type":"code","source":["import pyspark.sql.functions as F\n","\n","df_columns = df.columns\n","df_columns.remove(TARGET_COL)\n","\n","# Ensure the TARGET_COL is the last column\n","df = df.select(df_columns + [TARGET_COL]).withColumn(TARGET_COL, F.col(TARGET_COL).cast(\"int\"))\n","\n","if IS_SAMPLE:\n","    df = df.limit(SAMPLE_ROWS)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}},"cellStatus":"{}"},"id":"e09f453b-3b5d-4e21-b360-80e86e3f2045"},{"cell_type":"code","source":["df_pd = df.toPandas() # Convert Spark dataframe to Pandas dataframe for easier visualization and processing"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}},"cellStatus":"{}"},"id":"e38b4277-bf9d-45a0-8de7-bdabe5bcde0d"},{"cell_type":"code","source":["# The distribution of classes in the dataset\n","\n","print('No Frauds', round(df_pd['Class'].value_counts()[0]/len(df_pd) * 100,2), '% of the dataset')\n","print('Frauds', round(df_pd['Class'].value_counts()[1]/len(df_pd) * 100,2), '% of the dataset')"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":null,"statement_id":null,"state":"cancelled","livy_statement_state":null,"queued_time":"2023-08-23T12:21:18.1173174Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":"2023-08-23T12:21:19.863291Z","spark_jobs":null,"parent_msg_id":"ce2e1c3e-a8cd-49e6-a25b-c212f96bf480"},"text/plain":"StatementMeta(, , , Cancelled, )"},"metadata":{}}],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}},"cellStatus":"{}"},"id":"ad80f2d6-b7d9-4e6b-a422-073f39db0e5b"},{"cell_type":"markdown","source":["This shows that most of the transactions are non-fraudulent and therefore pre-processing is required prior to train any model to avoid any overfitting."],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"5d9abbc5-af21-4605-8edb-b945e63f4874"},{"cell_type":"markdown","source":["**Distribution of fraudulent versus non-fraudulent transactions.**"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"d3310edc-3976-4f49-b953-b80e48f91f73"},{"cell_type":"code","source":["import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","colors = [\"#0101DF\", \"#DF0101\"]\n","sns.countplot(x='Class', data=df_pd, palette=colors) \n","plt.title('Class Distributions \\n (0: No Fraud || 1: Fraud)', fontsize=10)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":null,"statement_id":null,"state":"cancelled","livy_statement_state":null,"queued_time":"2023-08-23T12:21:18.1182786Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":"2023-08-23T12:21:19.8634597Z","spark_jobs":null,"parent_msg_id":"bcac7245-2df6-435b-81ec-8e000f759df7"},"text/plain":"StatementMeta(, , , Cancelled, )"},"metadata":{}}],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}},"cellStatus":"{}"},"id":"46bec12c-ef32-41bc-8267-cf7e4ff2fa33"},{"cell_type":"markdown","source":["This clearly shows how imbalanced the dataset is."],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"79f44d44-084b-4a4d-bf52-6cae139b1c68"},{"cell_type":"markdown","source":["**Show the five-number summary (the minimum score, first quartile, median, third quartile, the maximum score) for the transaction amount using Box plots.**"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"4ccea93b-67f1-437e-b476-18b4d08a5a45"},{"cell_type":"code","source":["fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12,5))\n","s = sns.boxplot(ax = ax1, x=\"Class\", y=\"Amount\", hue=\"Class\",data=df_pd, palette=\"PRGn\", showfliers=True) # Remove outliers from the plot\n","s = sns.boxplot(ax = ax2, x=\"Class\", y=\"Amount\", hue=\"Class\",data=df_pd, palette=\"PRGn\", showfliers=False) # Kepp outliers from the plot\n","plt.show()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":null,"statement_id":null,"state":"cancelled","livy_statement_state":null,"queued_time":"2023-08-23T12:21:18.1188831Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":"2023-08-23T12:21:19.8636231Z","spark_jobs":null,"parent_msg_id":"22595972-45bf-4936-a6dc-22ed140f501e"},"text/plain":"StatementMeta(, , , Cancelled, )"},"metadata":{}}],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}},"cellStatus":"{}"},"id":"1629f99b-2a8b-494c-8059-e834a6f0cb18"},{"cell_type":"markdown","source":["Note that when the data is highly imbalanced, these plots may not demonstrate accurate insights because they will be affected by the imbalance between the classes. An alternative solution is to tackle the imbalance issue first and then create the same plots for more accurate insights."],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"d28e8617-4095-49d6-b06b-fdceeb4faef5"},{"cell_type":"markdown","source":["## Step 4: Model Training and Evaluation\n","\n","In this section, we train a LightGBM model to classify the fraud transactions. Note that we'll train the LightGBM model on both the imbalanced dataset as well as the balanced dataset (via SMOTE) and compare their performances.\n","\n","Prior to start the training, we split the data to the training and test datasets. Note that SMOTE should only be applied to the training dataset and we must leave the test dataset in its original imbalanced distribution in order to get a valid approximation of how the model will perform on the original data, which is representing the situation in production."],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"b701ff5f-eac6-4545-ae94-5526574a134f"},{"cell_type":"markdown","source":["### Prepare training and test datasets"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"ef3a65a9-109c-4163-a558-48348ee649da"},{"cell_type":"code","source":["# Split the dataset into training and test sets\n","from sklearn.model_selection import train_test_split\n","\n","train, test = train_test_split(df_pd, test_size=0.15)\n","feature_cols = [c for c in df_pd.columns.tolist() if c not in [TARGET_COL]]\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":null,"statement_id":null,"state":"cancelled","livy_statement_state":null,"queued_time":"2023-08-23T12:21:18.119839Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":"2023-08-23T12:21:19.8637944Z","spark_jobs":null,"parent_msg_id":"6e695ffc-b9cd-4382-b3e5-80463c9bab81"},"text/plain":"StatementMeta(, , , Cancelled, )"},"metadata":{}}],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}},"cellStatus":"{}"},"id":"656929df-8c39-4dda-975c-3f22229e5ba8"},{"cell_type":"markdown","source":["### Apply SMOTE to the training data to synthesize new samples for the minority class"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"052c3037-a2ff-40e8-bf97-971d37ff3da4"},{"cell_type":"code","source":["# Apply SMOTE to the training data\n","import pandas as pd\n","from collections import Counter\n","from imblearn.over_sampling import SMOTE\n","\n","X = train[feature_cols]\n","y = train[TARGET_COL]\n","print(\"Original dataset shape %s\" % Counter(y))\n","\n","sm = SMOTE(random_state=42)\n","X_res, y_res = sm.fit_resample(X, y)\n","print(\"Resampled dataset shape %s\" % Counter(y_res))\n","\n","new_train = pd.concat([X_res, y_res], axis=1)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":null,"statement_id":null,"state":"cancelled","livy_statement_state":null,"queued_time":"2023-08-23T12:21:18.1204805Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":"2023-08-23T12:21:19.8639683Z","spark_jobs":null,"parent_msg_id":"dcc8f628-1e3f-40b7-93d1-65d1678239dd"},"text/plain":"StatementMeta(, , , Cancelled, )"},"metadata":{}}],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}},"cellStatus":"{}"},"id":"9db1d797-6180-4907-abab-05c7e24c035f"},{"cell_type":"markdown","source":["### Model Training and Machine Learning Experiments\n","\n","Apache Spark in Microsoft Fabric enables machine learning with big data, providing the ability to obtain valuable insight from large amounts of structured, unstructured, and fast-moving data. There are several options when training machine learning models using Apache Spark in Microsoft Fabric: Apache Spark MLlib, SynapseML, and various other open-source libraries. You can learn about how to train machine learning models in Microsoft Fabric [here](https://aka.ms/fabric/MLTrain). \n","\n","A machine learning experiment is the primary unit of organization and control for all related machine learning runs. A run corresponds to a single execution of model code. Machine learning experiment tracking refers to the process of managing all the different experiments and their components, such as parameters, metrics, models and other artifacts and it enables to organize all the the required  components of a specific machine learning experiment as well as reproducing past results (easily) using saved experiments. You can learn more about machine learning experiments in Microsoft Fabric [here](https://aka.ms/synapse-experiment)."],"metadata":{},"id":"61631908-e5c0-4219-a747-7c013f3f143f"},{"cell_type":"markdown","source":["Update the MLflow autologging configuration to track additional metrics, parameters, files by setting  `exclusive=False`."],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"a42841b9-dd7a-4086-b80e-00d3a5821052"},{"cell_type":"code","source":["mlflow.autolog(exclusive=False)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":null,"statement_id":null,"state":"cancelled","livy_statement_state":null,"queued_time":"2023-08-23T12:21:18.121583Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":"2023-08-23T12:21:19.864136Z","spark_jobs":null,"parent_msg_id":"5cd2c2b6-3142-4cd7-8cbf-544ead588c91"},"text/plain":"StatementMeta(, , , Cancelled, )"},"metadata":{}}],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}},"cellStatus":"{}"},"id":"13746c04-daec-4aab-a6da-9dcbca177838"},{"cell_type":"markdown","source":["**Train the model using LightGBM.**\n","\n","We train using both the imbalanced dataset as well as the balanced dataset (via SMOTE) and then compare their performances."],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"13541648-10fd-40bf-ab4d-df7e6e3ec44f"},{"cell_type":"code","source":["import lightgbm as lgb\n","\n","model = lgb.LGBMClassifier(objective=\"binary\") # imbalanced dataset\n","smote_model = lgb.LGBMClassifier(objective=\"binary\") # balanced dataset"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":null,"statement_id":null,"state":"cancelled","livy_statement_state":null,"queued_time":"2023-08-23T12:21:18.1226937Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":"2023-08-23T12:21:19.8642947Z","spark_jobs":null,"parent_msg_id":"c19e8069-1991-4b0c-94c5-39dc2ae92065"},"text/plain":"StatementMeta(, , , Cancelled, )"},"metadata":{}}],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}},"cellStatus":"{}"},"id":"8ec73e3e-85d9-471a-b26b-0c07eb741940"},{"cell_type":"code","source":["# Train LightGBM for both imbalanced and balanced datasets and define the evaluation metrics\n","\n","print(\"Start training with imbalanced data:\\n\")\n","with mlflow.start_run(run_name=\"raw_data\") as raw_run:\n","    model = model.fit(\n","        train[feature_cols],\n","        train[TARGET_COL],\n","        eval_set=[(test[feature_cols], test[TARGET_COL])],\n","        eval_metric=\"auc\",\n","        callbacks=[\n","            lgb.log_evaluation(10),\n","        ],\n","    )\n","\n","print(f\"\\n\\nStart training with balanced data:\\n\")\n","with mlflow.start_run(run_name=\"smote_data\") as smote_run:\n","    smote_model = smote_model.fit(\n","        new_train[feature_cols],\n","        new_train[TARGET_COL],\n","        eval_set=[(test[feature_cols], test[TARGET_COL])],\n","        eval_metric=\"auc\",\n","        callbacks=[\n","            lgb.log_evaluation(10),\n","        ],\n","    )"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":null,"statement_id":null,"state":"cancelled","livy_statement_state":null,"queued_time":"2023-08-23T12:21:18.1235511Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":"2023-08-23T12:21:19.8644593Z","spark_jobs":null,"parent_msg_id":"700fc60c-36f2-4042-9d5d-3b265e913807"},"text/plain":"StatementMeta(, , , Cancelled, )"},"metadata":{}}],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}},"cellStatus":"{}"},"id":"66bd4e49-9ab0-4c01-a25c-70ad77becbf8"},{"cell_type":"markdown","source":["**Determine the feature importance for training with imbalanced dataset.**"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"f74a34e4-8edc-4ca9-9529-e91d785ea15c"},{"cell_type":"code","source":["with mlflow.start_run(run_id=raw_run.info.run_id):\n","    importance = lgb.plot_importance(\n","        model, title=\"Feature importance for imbalanced data\"\n","    )\n","    importance.figure.savefig(\"feauture_importance.png\")\n","    mlflow.log_figure(importance.figure, \"feature_importance.png\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":null,"statement_id":null,"state":"cancelled","livy_statement_state":null,"queued_time":"2023-08-23T12:21:18.1243723Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":"2023-08-23T12:21:19.8646238Z","spark_jobs":null,"parent_msg_id":"0592877a-dbb0-45f2-8a4e-15e8be19f7a9"},"text/plain":"StatementMeta(, , , Cancelled, )"},"metadata":{}}],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}},"cellStatus":"{}"},"id":"92d4a41d-cd6d-425c-b793-d9a4bc7f64e6"},{"cell_type":"markdown","source":["**Determine feature importance for training with balanced (via SMOTE) dataset.**"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"2fb06024-c70a-47bb-adf8-da7d094401d7"},{"cell_type":"code","source":["with mlflow.start_run(run_id=smote_run.info.run_id):\n","    smote_importance = lgb.plot_importance(\n","        smote_model, title=\"Feature importance for balanced (via SMOTE) data\"\n","    )\n","    smote_importance.figure.savefig(\"feauture_importance_smote.png\")\n","    mlflow.log_figure(smote_importance.figure, \"feauture_importance_smote.png\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":null,"statement_id":null,"state":"cancelled","livy_statement_state":null,"queued_time":"2023-08-23T12:21:18.1251117Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":"2023-08-23T12:21:19.8647948Z","spark_jobs":null,"parent_msg_id":"bb54e0c9-7246-4fbd-a690-c446c1e9a938"},"text/plain":"StatementMeta(, , , Cancelled, )"},"metadata":{}}],"execution_count":null,"metadata":{"cellStatus":"{}"},"id":"359d41c4-2783-43d9-9f46-1003c9fa90cd"},{"cell_type":"markdown","source":["Comparison of the above plots clearly demonstrates that the importance of features is drastically different between imbalanced versus balanced datasets."],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"a63616ea-8d67-4de3-9c63-0687cd7a3062"},{"cell_type":"markdown","source":["#### Model Evaluation"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"bb9e326e-d06b-458a-ae9f-8800f501948b"},{"cell_type":"markdown","source":["Below, we define a function that performs predictions and converts the prediction results into a Spark DataFrame so that we can later compute model statistics using [SynapseML](https://aka.ms/fabric/SynapseEval)."],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"763ea9a8-9e57-4336-8028-c9ae35ed368e"},{"cell_type":"code","source":["from pyspark.sql.functions import col\n","from pyspark.sql.types import IntegerType, DoubleType\n","\n","def prediction_to_spark(model, test):\n","    predictions = model.predict(test[feature_cols], num_iteration=model.best_iteration_)\n","    predictions = tuple(zip(test[TARGET_COL].tolist(), predictions.tolist()))\n","    dataColumns = [TARGET_COL, \"prediction\"]\n","    predictions = (\n","        spark.createDataFrame(data=predictions, schema=dataColumns)\n","        .withColumn(TARGET_COL, col(TARGET_COL).cast(IntegerType()))\n","        .withColumn(\"prediction\", col(\"prediction\").cast(DoubleType()))\n","    )\n","\n","    return predictions"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":null,"statement_id":null,"state":"cancelled","livy_statement_state":null,"queued_time":"2023-08-23T12:21:18.1258436Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":"2023-08-23T12:21:19.8649551Z","spark_jobs":null,"parent_msg_id":"680f1265-e954-4967-b150-b30431a03605"},"text/plain":"StatementMeta(, , , Cancelled, )"},"metadata":{}}],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}},"cellStatus":"{}"},"id":"872d3c90-39f8-498d-ab05-ad5fd9f88cb2"},{"cell_type":"markdown","source":["Below we perform predictions and compute the metrics for the model trained with raw data (imbalanced) and the model trained with balanced (via SMOTE) data."],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"3f51e29f-ae30-42f2-91d7-ac686028978b"},{"cell_type":"code","source":["predictions = prediction_to_spark(model, test)\n","smote_predictions = prediction_to_spark(smote_model, test)\n","predictions.limit(10).toPandas()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":null,"statement_id":null,"state":"cancelled","livy_statement_state":null,"queued_time":"2023-08-23T12:21:18.1265569Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":"2023-08-23T12:21:19.8651151Z","spark_jobs":null,"parent_msg_id":"683b23d6-c1cc-41f7-abeb-86a5ec6b098a"},"text/plain":"StatementMeta(, , , Cancelled, )"},"metadata":{}}],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}},"cellStatus":"{}"},"id":"b6f828c9-943a-4bbf-a8d2-a61c474594ba"},{"cell_type":"code","source":["from synapse.ml.train import ComputeModelStatistics\n","\n","metrics = ComputeModelStatistics(\n","    evaluationMetric=\"classification\", labelCol=TARGET_COL, scoredLabelsCol=\"prediction\"\n",").transform(predictions)\n","\n","smote_metrics = ComputeModelStatistics(\n","    evaluationMetric=\"classification\", labelCol=TARGET_COL, scoredLabelsCol=\"prediction\"\n",").transform(smote_predictions)\n","display(metrics)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":null,"statement_id":null,"state":"cancelled","livy_statement_state":null,"queued_time":"2023-08-23T12:21:18.1272947Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":"2023-08-23T12:21:19.8652769Z","spark_jobs":null,"parent_msg_id":"87a49eda-d813-4084-9a8e-7385a1662f4c"},"text/plain":"StatementMeta(, , , Cancelled, )"},"metadata":{}}],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}},"cellStatus":"{}"},"id":"95091793-1ae6-4bda-8629-2659c681cc66"},{"cell_type":"markdown","source":["#### Confusion Matrix\n","We use the confusion matrix in order to summarize the performances of the trained machine learning models on the test data. The matrix displays the number of true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN) produced by the model on the test data. Note that for binary classification, the matrix will be of a 2X2 table, For multi-class classification, the matrix shape will be equal to the number of classes i.e for n classes it will be a nXn table. "],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"0600de5b-2432-4b0b-b033-b6c8f11d9e3b"},{"cell_type":"code","source":["# Collect confusion matrix value\n","cm = metrics.select(\"confusion_matrix\").collect()[0][0].toArray()\n","smote_cm = smote_metrics.select(\"confusion_matrix\").collect()[0][0].toArray()\n","print(cm)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":null,"statement_id":null,"state":"cancelled","livy_statement_state":null,"queued_time":"2023-08-23T12:21:18.1283748Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":"2023-08-23T12:21:19.8655019Z","spark_jobs":null,"parent_msg_id":"3a07492a-9bd6-4fa9-b051-5f2a818309c3"},"text/plain":"StatementMeta(, , , Cancelled, )"},"metadata":{}}],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}},"cellStatus":"{}"},"id":"abd4b06a-3d1b-4e86-ae6d-9b81203313cf"},{"cell_type":"code","source":["# Plot confusion matrix\n","import seaborn as sns\n","\n","def plot(cm):\n","    \"\"\"\n","    Plot the confusion matrix.\n","    \"\"\"\n","    sns.set(rc={\"figure.figsize\": (5, 3.5)})\n","    ax = sns.heatmap(cm, annot=True, fmt=\".20g\")\n","    ax.set_title(\"Confusion Matrix\")\n","    ax.set_xlabel(\"Predicted label\")\n","    ax.set_ylabel(\"True label\")\n","    return ax\n","\n","with mlflow.start_run(run_id=smote_run.info.run_id):\n","    ax = plot(smote_cm)\n","    mlflow.log_figure(ax.figure, \"ConfusionMatrix.png\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":null,"statement_id":null,"state":"cancelled","livy_statement_state":null,"queued_time":"2023-08-23T12:21:18.1293072Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":"2023-08-23T12:21:19.8656753Z","spark_jobs":null,"parent_msg_id":"11f7af7a-9f77-4c77-add1-9248ee0b84ae"},"text/plain":"StatementMeta(, , , Cancelled, )"},"metadata":{}}],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}},"cellStatus":"{}"},"id":"c0bc2f8b-74c1-4a2c-b36c-defe52218ab5"},{"cell_type":"code","source":["with mlflow.start_run(run_id=raw_run.info.run_id):\n","    ax = plot(cm)\n","    mlflow.log_figure(ax.figure, \"ConfusionMatrix.png\")"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}},"cellStatus":"{}"},"id":"c999e79b-a5de-4320-a06e-8a1cb0deae55"},{"cell_type":"markdown","source":["#### Receiver Operating Characteristic Area Under the Curve and Area Under the Precision-Recall Curve\n","\n","The Area Under the Curve Receiver Operating Characteristic (AUC-ROC) measure is widely used to assess the performance of binary classifiers. However, sometimes, it is more appropriate to evaluate your classifier based on measuring the Area Under the Precision-Recall Curve (AUPRC). AUC-ROC is a chart that visualizes the trade-off between true positive rate (TPR) and false positive rate (FPR) whereas AUPRC is a curve that combines precision (PPV) and Recall (TPR) in a single visualization."],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"6e712950-5cd8-491e-a567-b692d9c65ecc"},{"cell_type":"code","source":["from pyspark.ml.evaluation import BinaryClassificationEvaluator\n","\n","def evaluate(predictions):\n","    \"\"\"\n","    Evaluate the model by computing AUROC and AUPRC with the predictions.\n","    \"\"\"\n","\n","    # Initialize the binary evaluator\n","    evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\", labelCol=TARGET_COL)\n","\n","    _evaluator = lambda metric: evaluator.setMetricName(metric).evaluate(predictions)\n","\n","    # Calculate AUROC, baseline 0.5\n","    auroc = _evaluator(\"areaUnderROC\")\n","    print(f\"The AUROC is: {auroc:.4f}\")\n","\n","    # Calculate AUPRC, baseline positive rate (0.172% in the data)\n","    auprc = _evaluator(\"areaUnderPR\")\n","    print(f\"The AUPRC is: {auprc:.4f}\")\n","\n","    return auroc, auprc\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"64263ff5-c40b-4765-b388-7839438564c9"},{"cell_type":"markdown","source":["**Log the AUC-ROC and AUPRC metrics for model that is trained on the imbalanced dataset.**"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"f68e661d-8e92-4b14-87d5-cad0300ab7a6"},{"cell_type":"code","source":["with mlflow.start_run(run_id=raw_run.info.run_id):\n","    auroc, auprc = evaluate(predictions)\n","    mlflow.log_metrics({\"AUPRC\": auprc, \"AUROC\": auroc})\n","    mlflow.log_params({\"Data_Enhancement\": \"None\", \"DATA_FILE\": DATA_FILE})"],"outputs":[],"execution_count":null,"metadata":{},"id":"b713a56c-9e0c-445f-beba-696fd09de42f"},{"cell_type":"markdown","source":["**Log the AUC-ROC and AUPRC metrics for the model that is trained on the balanced (via SMOTE) dataset.**"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"152120b5-5570-48f8-b412-ef03999bd626"},{"cell_type":"code","source":["with mlflow.start_run(run_id=smote_run.info.run_id):\n","    auroc, auprc = evaluate(smote_predictions)\n","    mlflow.log_metrics({\"AUPRC\": auprc, \"AUROC\": auroc})\n","    mlflow.log_params({\"Data_Enhancement\": \"SMOTE\", \"DATA_FILE\": DATA_FILE})"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"08a1bb3b-1fb9-47ec-8f67-0df4622a7779"},{"cell_type":"markdown","source":["As shown in the image below, any experiment with its respective name is logged and we will be able to track its parameters and performance metrics. We can also see that the models performs much better on the balanced dataset, since a higher AUROC indicates that the model is better at predicting 0 classes as 0 and 1 classes as 1.\n","\n","\n","<img style=\"float: left;\" src=\"https://synapseaisolutionsa.blob.core.windows.net/public/Credit_Card_Fraud_Detection/fraud-mlflow.png\"  width=\"45%\" height=\"10%\">\n","<img style=\"float: left;\" src=\"https://synapseaisolutionsa.blob.core.windows.net/public/Credit_Card_Fraud_Detection/fraud-logging.png\"  width=\"45%\" height=\"10%\"> \n","\n","\n"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"2cb1662d-23bc-44cd-9781-94c5aaf0f77f"},{"cell_type":"markdown","source":["## Step 5: Register the Model\n","\n","Use MLflow to register the models trained on both the imbalanced and balanced (via SMOTE) datasets."],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"32821d73-df8e-442c-94ea-3ed6b202b4a9"},{"cell_type":"code","source":["# Register the model\n","registered_model_name = f\"{EXPERIMENT_NAME}-lightgbm\"\n","\n","raw_model_uri = \"runs:/{}/model\".format(raw_run.info.run_id)\n","mlflow.register_model(raw_model_uri, registered_model_name)\n","\n","smote_model_uri = \"runs:/{}/model\".format(smote_run.info.run_id)\n","mlflow.register_model(smote_model_uri, registered_model_name)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"7ab74f27-d9d4-4a6a-9ea9-ad748f1a73e0"},{"cell_type":"markdown","source":["## Step 6: Save the Prediction Results\n","\n","Microsoft Fabric allows users to operationalize machine learning models with a scalable function called ```PREDICT```, which supports batch scoring in any compute engine.\n","\n","We can generate batch predictions directly from the Microsoft Fabric notebook or from a given model's item page. You can learn more about ```PREDICT``` and how to use it within Microsoft Fabric [here](https://aka.ms/fabric-predict).\n","\n","In this section, we'll deploy the model and save the prediction results."],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"19270bf2-e9f2-4a14-b37b-dffa70eda933"},{"cell_type":"code","source":["from synapse.ml.predict import MLFlowTransformer\n","\n","spark.conf.set(\"spark.synapse.ml.predict.enabled\", \"true\")\n","\n","model = MLFlowTransformer(\n","    inputCols=feature_cols,\n","    outputCol=\"prediction\",\n","    modelName=f\"{EXPERIMENT_NAME}-lightgbm\",\n","    modelVersion=2,\n",")\n","\n","test_spark = spark.createDataFrame(data=test, schema=test.columns.to_list())\n","\n","batch_predictions = model.transform(test_spark)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"4bd5337a-56c2-4e3e-86f3-36e2c4ab3e9e"},{"cell_type":"code","source":["# Save the predictions into the lakehouse\n","batch_predictions.write.format(\"delta\").mode(\"overwrite\").save(f\"{DATA_FOLDER}/predictions/batch_predictions\")"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"a7ef7893-a41e-4f09-a718-a4f4e59fc044"},{"cell_type":"code","source":["# Determine the entire runtime\n","batch_predictions.limit(5).toPandas()\n","print(f\"Full run cost {int(time.time() - ts)} seconds.\")"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"7b499738-7a5f-4cb0-98db-efe7a0926d3e"}],"metadata":{"language_info":{"name":"python"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"microsoft":{"language":"python","ms_spell_check":{"ms_spell_check_language":"en"},"host":{"trident":{"lakehouse":{"known_lakehouses":"[{\"id\":\"7135d238-0645-4a82-a272-8d5abcd4b84c\"}]","default_lakehouse":"7135d238-0645-4a82-a272-8d5abcd4b84c"}}}},"widgets":{},"kernel_info":{"name":"synapse_pyspark"},"nteract":{"version":"nteract-front-end@1.0.0"},"save_output":true,"spark_compute":{"compute_id":"/trident/default","session_options":{"enableDebugMode":false,"conf":{}}},"notebook_environment":{},"synapse_widget":{"version":"0.1","state":{}},"trident":{"lakehouse":{"default_lakehouse":"7135d238-0645-4a82-a272-8d5abcd4b84c","known_lakehouses":[{"id":"7135d238-0645-4a82-a272-8d5abcd4b84c"}],"default_lakehouse_name":"abhitest","default_lakehouse_workspace_id":"8938bbc6-c1ee-4169-942a-b757b586636b"}}},"nbformat":4,"nbformat_minor":5}